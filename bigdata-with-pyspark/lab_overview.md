<img align="right" src="./logo.png">

<h2><span style="color:red;"></span>Big Data with PySpark</h2>

**Analyze large datasets and discover techniques for testing, immunizing Spark jobs**

### Labs

Labs for this course are available at endpoints shared below. Update `<host-ip>` with the lab environment DNS and open following URL in browser to open jupyter workspace for the lab.

1. ##### Introduction
		* http://<host-ip>/lab/workspaces/lab1_introduction
2. ##### Getting Your Big Data into the Spark Environment Using RDDs
		* http://<host-ip>/lab/workspaces/lab2_rdd
3. ##### Big Data Cleaning and Wrangling with Spark Notebooks
		* http://<host-ip>/lab/workspaces/lab3_cleaning
4. ##### Aggregating and Summarizing Data into Useful Reports
		* http://<host-ip>/lab/workspaces/lab4_reports
5. ##### Powerful Exploratory Data Analysis with MLlib
		* http://<host-ip>/lab/workspaces/lab5_mlib
6. ##### Putting Structure on Your Big Data with SparkSQL
		* http://<host-ip>/lab/workspaces/lab6_sparksql

## Overview
Apache Spark is an open source parallel-processing framework that has been around for quite some time now. One of the many uses of Apache Spark is for data analytics applications across clustered computers. In this book, you will not only learn how to use Spark and the Python API to create high-performance analytics with big data, but also discover techniques for testing, immunizing, and parallelizing Spark jobs.

This module covers the following exciting features:
* Get practical big data experience while working on messy datasets
* Analyze patterns with Spark SQL to improve your business intelligence
* Use PySpark's interactive shell to speed up development time
