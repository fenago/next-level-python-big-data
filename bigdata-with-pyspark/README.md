# Big Data with PySpark

**Analyze large datasets and discover techniques for testing, immunizing Spark jobs**

## Overview
Apache Spark is an open source parallel-processing framework that has been around for quite some time now. One of the many uses of Apache Spark is for data analytics applications across clustered computers. In this book, you will not only learn how to use Spark and the Python API to create high-performance analytics with big data, but also discover techniques for testing, immunizing, and parallelizing Spark jobs.

This module covers the following exciting features:
* Get practical big data experience while working on messy datasets
* Analyze patterns with Spark SQL to improve your business intelligence
* Use PySpark's interactive shell to speed up development time
