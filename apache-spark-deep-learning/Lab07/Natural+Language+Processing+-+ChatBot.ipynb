{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Natural Language Processing\") \\\n",
    "   .config(\"spark.executor.memory\", \"6gb\") \\\n",
    "   .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('com.databricks.spark.csv')\\\n",
    "                    .options(header='true', inferschema='true')\\\n",
    "                    .load('TherapyBotSession.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('id', 'label', 'chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupBy(\"label\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"count\", ascending = False) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "df = df.withColumn('word_count',F.size(F.split(F.col('chat'),' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('label')\\\n",
    "    .agg(F.avg('word_count').alias('avg_word_count'))\\\n",
    "    .orderBy('avg_word_count', ascending = False) \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.select('id', 'word_count').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df_plot.set_index('id', inplace=True)\n",
    "df_plot.plot(kind='bar', figsize=(16, 6))\n",
    "plt.ylabel('Word Count')\n",
    "plt.title('Word Count distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def sentiment_score(chat):\n",
    "        return TextBlob(chat).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "sentiment_score_udf = F.udf(lambda x: sentiment_score(x), FloatType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('id', 'label', 'chat','word_count',\n",
    "                   sentiment_score_udf('chat').alias('sentiment_score'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('label')\\\n",
    "    .agg(F.avg('sentiment_score').alias('avg_sentiment_score'))\\\n",
    "    .orderBy('avg_sentiment_score', ascending = False) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('words',F.split(F.col('chat'),' '))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['i','me','my','myself','we','our','ours','ourselves',\n",
    "              'you','your','yours','yourself','yourselves','he','him',\n",
    "              'his','himself','she','her','hers','herself','it','its',\n",
    "              'itself','they','them','their','theirs','themselves',\n",
    "              'what','which','who','whom','this','that','these','those',\n",
    "              'am','is','are','was','were','be','been','being','have',\n",
    "              'has','had','having','do','does','did','doing','a','an',\n",
    "              'the','and','but','if','or','because','as','until','while',\n",
    "              'of','at','by','for','with','about','against','between',\n",
    "              'into','through','during','before','after','above','below',\n",
    "              'to','from','up','down','in','out','on','off','over','under',\n",
    "              'again','further','then','once','here','there','when','where',\n",
    "              'why','how','all','any','both','each','few','more','most',\n",
    "              'other','some','such','no','nor','not','only','own','same',\n",
    "              'so','than','too','very','can','will','just','don','should','now']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordsRemovalFeature = StopWordsRemover(inputCol=\"words\", \n",
    "                                           outputCol=\"words without stop\").setStopWords(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "stopWordRemovalPipeline = Pipeline(stages=[stopwordsRemovalFeature])\n",
    "pipelineFitRemoveStopWords = stopWordRemovalPipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pipelineFitRemoveStopWords.transform(df)\n",
    "df.select('words', 'words without stop').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = F.udf(lambda x: 1.0 if x == 'escalate' else 0.0, FloatType())\n",
    "df = df.withColumn('label', label('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.feature as feat\n",
    "TF_ = feat.HashingTF(inputCol=\"words without stop\", \n",
    "                     outputCol=\"rawFeatures\", numFeatures=100000)\n",
    "IDF_ = feat.IDF(inputCol=\"rawFeatures\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineTFIDF = Pipeline(stages=[TF_, IDF_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineFit = pipelineTFIDF.fit(df)\n",
    "df = pipelineFit.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('label', 'rawFeatures','features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingDF, testDF) = df.randomSplit([0.75, 0.25], seed = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "logreg = LogisticRegression(regParam=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregModel = logreg.fit(trainingDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionDF = logregModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionDF.select('label', 'probability', 'prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionDF.crosstab('label', 'prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "actual = predictionDF.select('label').toPandas()\n",
    "predicted = predictionDF.select('prediction').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy score: {}%'.format(round(metrics.accuracy_score(actual, predicted),3)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "scores = predictionDF.select('label', 'rawPrediction')\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print('The ROC score is {}%'.format(round(evaluator.evaluate(scores),3)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictionDF.describe('label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
