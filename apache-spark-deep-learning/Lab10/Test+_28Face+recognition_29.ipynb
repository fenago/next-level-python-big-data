{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten \n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading images from the local drive \n",
    "mypath='MIT-CBCL-facerec-database//training-synthetic' \n",
    "onlyfiles= [ f for f in listdir(mypath) if isfile(join(mypath,f)) ] \n",
    "images =np.empty([3240,200,200],dtype=int)\n",
    "for n in range(0, len(onlyfiles)):\n",
    " images[n] = mpimg.imread( join(mypath,onlyfiles[n]) ).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow (images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow (images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt. imshow (images[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[3119])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =np.empty([3240,1],dtype=int) \n",
    "for x in range(0, len(onlyfiles)):\n",
    "    if onlyfiles[x][3]=='0': y[x]=0\n",
    "    elif onlyfiles[x][3]=='1': y[x]=1\n",
    "    elif onlyfiles[x][3]=='2': y[x]=2\n",
    "    elif onlyfiles[x][3]=='3': y[x]=3\n",
    "    elif onlyfiles[x][3]=='4': y[x]=4\n",
    "    elif onlyfiles[x][3]=='5': y[x]=5\n",
    "    elif onlyfiles[x][3]=='6': y[x]=6\n",
    "    elif onlyfiles[x][3]=='7': y[x]=7\n",
    "    elif onlyfiles[x][3]=='8': y[x]=8\n",
    "    elif onlyfiles[x][3]=='9': y[x]=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion for cropping images to obtain only the significant part \n",
    "def crop(img):\n",
    "    a=28*np.ones(len(img)) #background has pixel intensity of 28 \n",
    "    b=np.where((img== a).all(axis=1)) #check image background\n",
    "    img=np.delete(img,(b),0) #deleting the unwanted part from the Y axis \n",
    "    plt.imshow(img)\n",
    "    img=img.transpose()\n",
    "    d=28*np.ones(len(img[0]))\n",
    "    e=np.where((img== d).all(axis=1))\n",
    "    img=np.delete(img,e,0) #deleting the unwanted part from the X axis \n",
    "    img=img.transpose()\n",
    "    print (img.shape) #printing image shape to ensure it is actually being cropped\n",
    "    super_threshold_indices = img < 29 #padding zeros instead of background data  \n",
    "    img[super_threshold_indices] = 0\n",
    "    plt.imshow (img)\n",
    "    return img[0:150, 0:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropping all the images\n",
    "image = np.empty([3240,150,128],dtype=int) \n",
    "for n in range(0, len(images)):\n",
    " image[n]=crop(images[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (image[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (image[22].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly splitting data into training(80%) and test(20%) sets \n",
    "test_ind=np.random.choice(range(3240), 648, replace=False) \n",
    "train_ind=np.delete(range(0,len(onlyfiles)),test_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segregating the training and test images \n",
    "x_train=image[train_ind] \n",
    "y1_train=y[train_ind] \n",
    "x_test=image[test_ind] \n",
    "y1_test=y[test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping the input images\n",
    "x_train = x_train.reshape(x_train.shape[0], 128, 150, 1) \n",
    "x_test = x_test.reshape(x_test.shape[0], 128, 150, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting data to float32\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing data\n",
    "x_train/=255 \n",
    "x_test/=255\n",
    "#10 digits represent the 10 classes \n",
    "number_of_persons = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data to vectors\n",
    "y_train = np_utils.to_categorical(y1_train, number_of_persons) \n",
    "y_test = np_utils.to_categorical(y1_test, number_of_persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), input_shape=(128,150,1))) #Input layer \n",
    "model.add(Activation('relu')) # 'relu' as activation function\n",
    "model.add(Conv2D(16, (3, 3))) #first hidden layer\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) # Maxpooling from (2,2)\n",
    "model.add(Conv2D(16,(3, 3))) # second hidden layer \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) # Maxpooling from (2,2)\n",
    "model.add(Flatten()) #flatten the maxpooled data\n",
    "# Fully connected layer\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25)) #Dropout is applied to overcome overfitting \n",
    "model.add(Dense(10)) \n",
    "#output layer\n",
    "model.add(Activation('softmax')) # 'softmax' is used for SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model compliation\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation to reduce overfitting problem\n",
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3, \n",
    "                         height_shift_range=0.08,zoom_range=0.08)\n",
    "test_gen = ImageDataGenerator()\n",
    "train_generator = gen.flow(x_train, y_train, batch_size=16) \n",
    "test_generator = test_gen.flow(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model fitting\n",
    "model.fit_generator(train_generator, epochs=5, validation_data=test_generator) \n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(x_test, y_test, verbose=0) \n",
    "print(\"Recognition Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
