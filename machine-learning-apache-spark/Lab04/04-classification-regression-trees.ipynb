{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Import the required Python dependencies\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Instantiate a Spark Context\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"CART - Congressional Voting\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) Load the Congressional Voting dataset (data/congressional-voting-data/house-votes-84.csv) into a Spark DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"party\", StringType()),\n",
    "    StructField(\"handicapped_infants\", StringType()),\n",
    "    StructField(\"water_project_cost_sharing\", StringType()),\n",
    "    StructField(\"adoption_of_the_budget_resolution\", StringType()),\n",
    "    StructField(\"physician_fee_freeze\", StringType()),\n",
    "    StructField(\"el_salvador_aid\", StringType()),\n",
    "    StructField(\"religious_groups_in_schools\", StringType()),\n",
    "    StructField(\"anti_satellite_test_ban\", StringType()),\n",
    "    StructField(\"aid_to_nicaraguan_contras\", StringType()),\n",
    "    StructField(\"mx_missile\", StringType()),\n",
    "    StructField(\"immigration\", StringType()),\n",
    "    StructField(\"synfuels_corporation_cutback\", StringType()),\n",
    "    StructField(\"education_spending\", StringType()),\n",
    "    StructField(\"superfund_right_to_sue\", StringType()),\n",
    "    StructField(\"crime\", StringType()),\n",
    "    StructField(\"duty_free_exports\", StringType()),\n",
    "    StructField(\"export_administration_act_south_africa\", StringType())\n",
    "])\n",
    "\n",
    "congressional_voting_df = sqlContext.read.format('com.databricks.spark.csv').schema(schema).options(header = 'false', inferschema = 'false').load('./data/congressional-voting-data/house-votes-84.data')\n",
    "congressional_voting_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) Index the relevant categorical and label variables using a Pipeline of stages\n",
    "categorical_columns = ['handicapped_infants', 'water_project_cost_sharing', 'adoption_of_the_budget_resolution', 'physician_fee_freeze', 'el_salvador_aid', 'religious_groups_in_schools', 'anti_satellite_test_ban', 'aid_to_nicaraguan_contras', 'mx_missile', 'immigration', 'synfuels_corporation_cutback', 'education_spending', 'superfund_right_to_sue', 'crime', 'duty_free_exports', 'export_administration_act_south_africa']\n",
    "pipeline_stages = []\n",
    "for categorial_column in categorical_columns:\n",
    "    string_indexer = StringIndexer(inputCol = categorial_column, outputCol = categorial_column + 'Index')\n",
    "    encoder = OneHotEncoder(inputCols = [string_indexer.getOutputCol()], outputCols=[categorial_column + \"classVec\"])\n",
    "    pipeline_stages += [string_indexer, encoder]\n",
    "    \n",
    "label_string_idx = StringIndexer(inputCol = 'party', outputCol = 'label')\n",
    "pipeline_stages += [label_string_idx]\n",
    "vector_assembler_inputs = [c + \"classVec\" for c in categorical_columns]\n",
    "vector_assembler = VectorAssembler(inputCols = vector_assembler_inputs, outputCol = \"features\")\n",
    "pipeline_stages += [vector_assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) Generate Input Feature Vectors from the Raw Spark DataFrame by executing the previously constructed Pipeline\n",
    "pipeline = Pipeline(stages = pipeline_stages)\n",
    "pipeline_model = pipeline.fit(congressional_voting_df)\n",
    "label_column = 'label'\n",
    "congressional_voting_features_df = pipeline_model.transform(congressional_voting_df).select(['features', label_column, 'party'])\n",
    "pd.DataFrame(congressional_voting_features_df.take(5), columns=congressional_voting_features_df.columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6) Split the Raw Features and Labelled DataFrame into a Training DataFrame and a Test DataFrame\n",
    "train_df, test_df = congressional_voting_features_df.randomSplit([0.75, 0.25], seed=12345)\n",
    "train_df.count(), test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (7) Train a Classification Tree Model on the Training DataFrame\n",
    "decision_tree = DecisionTreeClassifier(featuresCol = 'features', labelCol = label_column)\n",
    "decision_tree_model = decision_tree.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (8) Apply the Trained Classification Tree Model to the Test DataFrame to make predictions\n",
    "test_decision_tree_predictions_df = decision_tree_model.transform(test_df)\n",
    "print(\"TEST DATASET PREDICTIONS AGAINST ACTUAL LABEL: \")\n",
    "test_decision_tree_predictions_df.select(\"probability\", \"rawPrediction\", \"prediction\", label_column, \"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (9) Evaluate the performance of our Classification Tree Model on the Test DataFrame using Area under a ROC curve\n",
    "evaluator_roc_area = BinaryClassificationEvaluator(rawPredictionCol = \"rawPrediction\", labelCol = label_column, metricName = \"areaUnderROC\")\n",
    "print(\"Area Under ROC Curve on Test Data = %g\" % evaluator_roc_area.evaluate(test_decision_tree_predictions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10) Visualise the Classification Tree\n",
    "print(str(decision_tree_model.toDebugString))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (11) Train a Random Forest Classifier Model on the Training DataFrame\n",
    "random_forest = RandomForestClassifier(featuresCol = 'features', labelCol = label_column)\n",
    "random_forest_model = random_forest.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (12) Apply the Trained Random Forest Classifier Model to the Test DataFrame to make predictions\n",
    "test_random_forest_predictions_df = random_forest_model.transform(test_df)\n",
    "print(\"TEST DATASET PREDICTIONS AGAINST ACTUAL LABEL: \")\n",
    "test_random_forest_predictions_df.select(\"probability\", \"rawPrediction\", \"prediction\", label_column, \"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (13) Evaluate the performance of our Random Forest Classifier Model on the Test DataFrame using Area under a ROC curve\n",
    "evaluator_rf_roc_area = BinaryClassificationEvaluator(rawPredictionCol = \"rawPrediction\", labelCol = label_column, metricName = \"areaUnderROC\")\n",
    "print(\"Area Under ROC Curve on Test Data = %g\" % evaluator_rf_roc_area.evaluate(test_random_forest_predictions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (14) Stop the Spark Context\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
