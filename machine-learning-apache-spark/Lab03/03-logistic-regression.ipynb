{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Import the required Python dependencies\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Instantiate a Spark Context\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"Logistic Regression - Breast Cancer\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) Load the Breast Cancer dataset (data/breast-cancer-data/dataR2.csv) into a Spark DataFrame\n",
    "breast_cancer_df = sqlContext.read.format('com.databricks.spark.csv').options(header = 'true', inferschema = 'true').load('./data/breast-cancer-data/dataR2.csv')\n",
    "breast_cancer_df = breast_cancer_df.withColumnRenamed('MCP.1', 'MCP_1')\n",
    "indexer = StringIndexer(inputCol = \"Classification\", outputCol = \"label\").fit(breast_cancer_df)\n",
    "breast_cancer_df = indexer.transform(breast_cancer_df)\n",
    "breast_cancer_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) Calculate standard statistical descriptive analytics on the raw Breast Cancer Spark DataFrame\n",
    "breast_cancer_df.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) Generate Input Feature Vectors from the Raw Spark DataFrame\n",
    "feature_columns = ['Age', 'BMI', 'Glucose', 'Insulin', 'HOMA', 'Leptin', 'Adiponectin', 'Resistin', 'MCP_1']\n",
    "label_column = 'label'\n",
    "vector_assembler = VectorAssembler(inputCols = feature_columns, outputCol = 'features')\n",
    "breast_cancer_features_df = vector_assembler.transform(breast_cancer_df).select(['features', label_column])\n",
    "breast_cancer_features_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6) Split the Raw DataFrame into a Training DataFrame and a Test DataFrame\n",
    "train_df, test_df = breast_cancer_features_df.randomSplit([0.75, 0.25], seed=12345)\n",
    "train_df.count(), test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (7) Train a Logistic Regression Model on the Training DataFrame\n",
    "logistic_regression = LogisticRegression(featuresCol = 'features', labelCol = label_column)\n",
    "logistic_regression_model = logistic_regression.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (8) Output Logistic Regression Model Summary Statistics to evaluate the Training Model\n",
    "print(\"Model Coefficients: \" + str(logistic_regression_model.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(logistic_regression_model.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (9) Apply the Trained Logistic Regression Model to the Test DataFrame to make predictions\n",
    "test_logistic_regression_predictions_df = logistic_regression_model.transform(test_df)\n",
    "print(\"TEST DATASET PREDICTIONS AGAINST ACTUAL LABEL: \")\n",
    "test_logistic_regression_predictions_df.select(\"probability\", \"rawPrediction\", \"prediction\", label_column, \"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10) Evaluate the performance of our Logistic Regression Model on the Test DataFrame using Area under a ROC curve\n",
    "test_summary = logistic_regression_model.evaluate(test_df)\n",
    "roc = test_summary.roc.toPandas()\n",
    "plt.plot(roc['FPR'],roc['TPR'])\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.xlabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "evaluator_roc_area = BinaryClassificationEvaluator(rawPredictionCol = \"rawPrediction\", labelCol = label_column, metricName = \"areaUnderROC\")\n",
    "print(\"Area Under ROC Curve on Test Data = %g\" % evaluator_roc_area.evaluate(test_logistic_regression_predictions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (11) Generate a Confusion/Classification Matrix\n",
    "N = test_logistic_regression_predictions_df.count()\n",
    "true_positives = test_logistic_regression_predictions_df.filter( col(\"prediction\") == 1.0 ).filter( col(\"label\") == 1.0 ).count()\n",
    "true_negatives = test_logistic_regression_predictions_df.filter( col(\"prediction\") == 0.0 ).filter( col(\"label\") == 0.0 ).count()\n",
    "false_positives = test_logistic_regression_predictions_df.filter( col(\"prediction\") == 1.0 ).filter( col(\"label\") == 0.0 ).count()\n",
    "false_negatives = test_logistic_regression_predictions_df.filter( col(\"prediction\") == 0.0 ).filter( col(\"label\") == 1.0 ).count()\n",
    "print(\"N = %g\" % N)\n",
    "print(\"Overall Accuracy = %g\" % ((true_negatives + true_positives)/N))\n",
    "print(\"Overall Error Rate = %g\" % ((false_negatives + false_positives)/N))\n",
    "print(\"Sensitivity = %g\" % (true_positives / (true_positives + false_negatives)))\n",
    "print(\"Specificity = %g\" % (true_negatives / (true_negatives + false_positives)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (12) Alternatively we can generate the same Classification Matrix using the MLLib RDD API (Maintenance Mode as of Spark 2.3.2)\n",
    "predictions_and_label = test_logistic_regression_predictions_df.select(\"prediction\", \"label\").rdd\n",
    "metrics = MulticlassMetrics(predictions_and_label)\n",
    "print(\"N = %g\" % N)\n",
    "print(metrics.confusionMatrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (13) Stop the Spark Context\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
