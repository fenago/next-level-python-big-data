{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Import the required Python dependencies\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Instantiate a Spark Context\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"Multilayer Perceptron - OCR\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) Load the Letter Recognition Dataset (in CSV format with pre-defined label and features columns)\n",
    "# (3.1) Create Feature Vectors from the 16 features\n",
    "# (3.2) Rename the 'lettr' column to 'label' which is a number representing one of the 26 characters in the English alphabet\n",
    "\n",
    "letter_recognition_df = sqlContext.read.format('com.databricks.spark.csv').options(header = 'true', inferschema = 'true').load('./data/ocr-data/letter-recognition.csv')\n",
    "feature_columns = ['x-box','y-box','width','high','onpix','x-bar','y-bar','x2bar','y2bar','xybar','x2ybr','xy2br','x-ege','xegvy','y-ege','yegvx']\n",
    "vector_assembler = VectorAssembler(inputCols = feature_columns, outputCol = 'features')\n",
    "vectorised_df = vector_assembler.transform(letter_recognition_df).withColumnRenamed('lettr', 'label').select('label', 'features')\n",
    "vectorised_df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) Split the Featurised DataFrame into a Training DataFrame and a Test DataFrame\n",
    "train_df, test_df = vectorised_df.randomSplit([0.75, 0.25], seed=12345)\n",
    "train_df.count(), test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) Specify the layers for our Neural Network\n",
    "# (5.1) The 1st element in this list represents the size of the Input Layer. In our case, we have 16 features\n",
    "# (5.2) The next elements in the list represent the sizes of the intermediate Hidden Layers, in our case 8 and 4\n",
    "# (5.3) The final element in this list represents the size of the Output. In our case, we have 26 classes\n",
    "layers = [16, 8, 4, 26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6) Train a Multilayer Perceptron Classifier using our list representing our layers from input to output layers\n",
    "multilayer_perceptron_classifier = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "multilayer_perceptron_classifier_model = multilayer_perceptron_classifier.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (7) Apply the Trained Multilayer Perceptron Classifier Model to the Test DataFrame to make predictions\n",
    "test_predictions_df = multilayer_perceptron_classifier_model.transform(test_df)\n",
    "print(\"TEST DATASET PREDICTIONS AGAINST ACTUAL LABEL: \")\n",
    "test_predictions_df.select(\"label\", \"features\", \"probability\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (8) Compute the accuracy of our Trained Multilayer Perceptron Classifier Model on the Test DataFrame\n",
    "prediction_and_labels = test_predictions_df.select(\"prediction\", \"label\")\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "precision_evaluator = MulticlassClassificationEvaluator(metricName=\"weightedPrecision\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(metricName=\"weightedRecall\")\n",
    "print(\"Accuracy on Test Dataset = %g\" % accuracy_evaluator.evaluate(prediction_and_labels))\n",
    "print(\"Precision on Test Dataset = %g\" % precision_evaluator.evaluate(prediction_and_labels))\n",
    "print(\"Recall on Test Dataset = %g\" % recall_evaluator.evaluate(prediction_and_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (9) To improve the accuracy of our model, let us increase the size of the Hidden Layers\n",
    "new_layers = [16, 16, 12, 26]\n",
    "new_multilayer_perceptron_classifier = MultilayerPerceptronClassifier(maxIter=400, layers=new_layers, blockSize=128, seed=1234)\n",
    "new_multilayer_perceptron_classifier_model = new_multilayer_perceptron_classifier.fit(train_df)\n",
    "new_test_predictions_df = new_multilayer_perceptron_classifier_model.transform(test_df)\n",
    "print(\"New Accuracy on Test Dataset = %g\" % accuracy_evaluator.evaluate(new_test_predictions_df.select(\"prediction\", \"label\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10) Stop the Spark Context\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
