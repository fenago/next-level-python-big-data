{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Import the required Python dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Instantiate a Spark Context\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"Principal Component Analysis - Movie Ratings\").set(\"spark.driver.memory\", \"4g\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) Load the Pivoted User Movie Ratings into a Spark DataFrame and examine its dimensions\n",
    "user_movie_ratings_df = sqlContext.read.format('com.databricks.spark.csv').options(header = 'true', inferschema = 'true', delimiter = '|').load('./data/movie-ratings-data/user-movie-ratings.csv')\n",
    "print((user_movie_ratings_df.count(), len(user_movie_ratings_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) Generate MLlib Feature Vectors from all the 3000 (i.e. minus userId column) dimensions (movies)\n",
    "feature_columns = user_movie_ratings_df.columns\n",
    "feature_columns.remove('userId')\n",
    "vector_assembler = VectorAssembler(inputCols = feature_columns, outputCol = 'features')\n",
    "user_movie_ratings_features_df = vector_assembler.transform(user_movie_ratings_df).select(['userId', 'features'])\n",
    "user_movie_ratings_features_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) Standardise the data by scaling the features to have zero mean and unit standard deviation\n",
    "standardizer = StandardScaler(withMean=True, withStd=True, inputCol='features', outputCol='std_features')\n",
    "standardizer_model = standardizer.fit(user_movie_ratings_features_df)\n",
    "user_movie_ratings_standardized_features_df = standardizer_model.transform(user_movie_ratings_features_df)\n",
    "user_movie_ratings_standardized_features_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6) Generate a RowMatrix (distributed Matrix with no index where each Row is a vector) from the scaled features DataFrame\n",
    "scaled_features_rows_rdd = user_movie_ratings_standardized_features_df.select(\"std_features\").rdd\n",
    "scaled_features_matrix = RowMatrix(scaled_features_rows_rdd.map(lambda x: x[0].tolist()))\n",
    "print(\"Scaled Features Matrix Dimensions: \\n\")\n",
    "print((scaled_features_matrix.numRows(), scaled_features_matrix.numCols()))\n",
    "print(\"\\nScaled Features Matrix (1st Row/Vector with 3000 elements): \\n\")\n",
    "scaled_features_matrix_collected = scaled_features_matrix.rows.collect()\n",
    "print(scaled_features_matrix_collected[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (7) Compute the top 300 principal components (eigenvectors sorted by their corresponding eigenvalues)\n",
    "number_principal_components = 300\n",
    "principal_components = scaled_features_matrix.computePrincipalComponents(number_principal_components)\n",
    "print(\"Top %d Principal Components: \\n\" % number_principal_components)\n",
    "print(principal_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (8) Project the original User Movie Ratings dataset from 3000 dimensions into 300 dimensions\n",
    "# (via Matrix multiplication of the scaled features matrix with the matrix of principal components)\n",
    "projected_matrix = scaled_features_matrix.multiply(principal_components)\n",
    "print(\"Projected Matrix Dimensions: \\n\")\n",
    "print((projected_matrix.numRows(), projected_matrix.numCols()))\n",
    "print(\"\\nProjected Matrix (1st Row/Vector with 300 elements): \\n\")\n",
    "projected_matrix_collected = projected_matrix.rows.collect()\n",
    "print(projected_matrix_collected[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (9) Alternatively use MLlib's PCA estimator directly on the scaled DataFrame\n",
    "pca = PCA(k=number_principal_components, inputCol=\"std_features\", outputCol=\"pca_features\")\n",
    "pca_model = pca.fit(user_movie_ratings_standardized_features_df)\n",
    "user_movie_ratings_pca_df = pca_model.transform(user_movie_ratings_standardized_features_df)\n",
    "user_movie_ratings_pca_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10) Extract the Explained Variance (vector of proportions of variance explained) for each Principal Component\n",
    "pca_model.explainedVariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (11) Stop the Spark Context\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
